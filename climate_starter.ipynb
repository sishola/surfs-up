{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import style\n",
    "style.use('fivethirtyeight')\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "from dateutil import relativedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reflect Tables into SQLAlchemy ORM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python SQL toolkit and Object Relational Mapper\n",
    "import sqlalchemy\n",
    "from sqlalchemy.ext.automap import automap_base\n",
    "from sqlalchemy.orm import Session\n",
    "from sqlalchemy import create_engine, func, desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(\"sqlite:///Resources/hawaii.sqlite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reflect an existing database into a new model\n",
    "Base = automap_base()\n",
    "# reflect the tables\n",
    "Base.prepare(engine, reflect=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['measurement', 'station']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can view all of the classes that automap found\n",
    "Base.classes.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save references to each table\n",
    "Measurement = Base.classes.measurement\n",
    "Station = Base.classes.station"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our session (link) from Python to the DB\n",
    "session = Session(engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Climate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id, INTEGER\n",
      "station, TEXT\n",
      "date, TEXT\n",
      "prcp, FLOAT\n",
      "tobs, FLOAT\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import inspect\n",
    "#date = dt.datetime(2011, 5, 31)\n",
    "inspector = inspect(engine)\n",
    "for column in inspector.get_columns('Measurement'):\n",
    "    print(f\"{column['name']}, {column['type']}\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Design a query to retrieve the last 12 months of precipitation data and plot the results\n",
    "\n",
    "# Calculate the date 1 year ago from the last data point in the database\n",
    "maxDate = session.query( func.max(Measurement.date).label('maxdate')).all()\n",
    "maxDate = list(np.ravel(maxDate))\n",
    "\n",
    "maxDate=pd.to_datetime(maxDate[0])\n",
    "\n",
    "minDate = maxDate- relativedelta.relativedelta(months=12)\n",
    "#minDate = maxDate- dt.timedelta(weeks=52)\n",
    "\n",
    "# Perform a query to retrieve the data and precipitation scores\n",
    "results = session.query(Measurement.date , Measurement.prcp).filter( Measurement.date >= minDate.date()).all()\n",
    "\n",
    "# Save the query results as a Pandas DataFrame and set the index to the date column\n",
    "df = pd.DataFrame(results, columns=['date', 'prcp'])\n",
    "df = df.rename(columns = {'prcp':'precipitation'})\n",
    "df.set_index('date',inplace=True)\n",
    "\n",
    "# Sort the dataframe by date\n",
    "df = df.sort_index()\n",
    "\n",
    "# Use Pandas Plotting with Matplotlib to plot the data\n",
    "df.plot.bar()\n",
    "plt.tight_layout()\n",
    "plt.tick_params(axis='x',  which='both', bottom=False, top=False, labelbottom=False) \n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![precipitation](Images/precipitation.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precipitation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2021.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.177279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.461190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.130000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.700000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       precipitation\n",
       "count    2021.000000\n",
       "mean        0.177279\n",
       "std         0.461190\n",
       "min         0.000000\n",
       "25%         0.000000\n",
       "50%         0.020000\n",
       "75%         0.130000\n",
       "max         6.700000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use Pandas to calcualte the summary statistics for the precipitation data\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![describe](Images/describe.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of stations: 9\n"
     ]
    }
   ],
   "source": [
    "# Design a query to show how many stations are available in this dataset?\n",
    "\n",
    "numOfStations = session.query(Measurement.station).distinct(Measurement.station).group_by(Measurement.station).count()\n",
    "print(f'Number of stations: {numOfStations}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('USC00519281', 2772),\n",
       " ('USC00519397', 2724),\n",
       " ('USC00513117', 2709),\n",
       " ('USC00519523', 2669),\n",
       " ('USC00516128', 2612),\n",
       " ('USC00514830', 2202),\n",
       " ('USC00511918', 1979),\n",
       " ('USC00517948', 1372),\n",
       " ('USC00518838', 511)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What are the most active stations? (i.e. what stations have the most rows)?\n",
    "# List the stations and the counts in descending order.\n",
    "\n",
    "session.query(Measurement.station, func.count(Measurement.station)).group_by(Measurement.station).order_by(desc(func.count(Measurement.station))).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Station USC00519281: Lowest temperature- 0.0, Highest Temperature-9.64 & Average Temperature-0.2123520923520915\n"
     ]
    }
   ],
   "source": [
    "# Using the station id from the previous query, calculate the lowest temperature recorded, \n",
    "# highest temperature recorded, and average temperature most active station?\n",
    "results = session.query(Measurement.station, func.min(Measurement.prcp).label(\"low\"), func.max(Measurement.prcp).label(\"high\"), func.avg(Measurement.prcp).label(\"avg\")).\\\n",
    "    filter(Measurement.station=='USC00519281').\\\n",
    "    group_by(Measurement.station).all()\n",
    "df = pd.DataFrame(results)\n",
    "#print(df.loc[0,'station'])\n",
    "print(f\"Station {df.loc[0,'station']}: Lowest temperature- {df.loc[0,'low']}, Highest Temperature-{df.loc[0,'high']} & Average Temperature-{df.loc[0,'avg']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the station with the highest number of temperature observations.\n",
    "# Query the last 12 months of temperature observation data for this station and plot the results as a histogram\n",
    "\n",
    "result = session.query(Measurement.station, func.count(Measurement.prcp)).\\\n",
    "    group_by(Measurement.station).order_by(desc(func.count(Measurement.prcp))).limit(1).all()\n",
    "\n",
    "\n",
    "stationHighNumTemp = list(np.ravel(result))[0]                   \n",
    "\n",
    "\n",
    "maxDate = session.query( func.max(Measurement.date)).filter(Measurement.station==stationHighNumTemp).all()\n",
    "\n",
    "maxDate = list(np.ravel(maxDate))\n",
    "\n",
    "maxDate=pd.to_datetime(maxDate[0])\n",
    "\n",
    "minDate = maxDate- relativedelta.relativedelta(months=12)\n",
    "#minDate = maxDate- dt.timedelta(weeks=52)\n",
    "\n",
    "# Perform a query to retrieve the data and precipitation scores\n",
    "results = session.query(Measurement.date , Measurement.prcp).filter( Measurement.date >= minDate.date()).all()\n",
    "\n",
    "\n",
    "df = pd.DataFrame(results, columns=['date', 'prcp'])\n",
    "df = df.rename(columns = {'prcp':'precipitation'})\n",
    "df.set_index('date',inplace=True)\n",
    "\n",
    "# Sort the dataframe by date\n",
    "df = df.sort_index()\n",
    "\n",
    "# Use Pandas Plotting with Matplotlib to plot the data\n",
    "df.plot.bar()\n",
    "plt.tight_layout()\n",
    "plt.tick_params(axis='x',  which='both', bottom=False, top=False, labelbottom=False) \n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![precipitation](Images/station-histogram.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function called `calc_temps` will accept start date and end date in the format '%Y-%m-%d' \n",
    "# and return the minimum, average, and maximum temperatures for that range of dates\n",
    "def calc_temps(start_date, end_date):\n",
    "    \"\"\"TMIN, TAVG, and TMAX for a list of dates.\n",
    "    \n",
    "    Args:\n",
    "        start_date (string): A date string in the format %Y-%m-%d\n",
    "        end_date (string): A date string in the format %Y-%m-%d\n",
    "        \n",
    "    Returns:\n",
    "        TMIN, TAVE, and TMAX\n",
    "    \"\"\"\n",
    "    \n",
    "    return session.query(func.min(Measurement.tobs), func.avg(Measurement.tobs), func.max(Measurement.tobs)).\\\n",
    "        filter(Measurement.date >= start_date).filter(Measurement.date <= end_date).all()\n",
    "\n",
    "# function usage example\n",
    "print(calc_temps('2012-02-28', '2012-03-05'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use your previous function `calc_temps` to calculate the tmin, tavg, and tmax \n",
    "# for your trip using the previous year's data for those same dates.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results from your previous query as a bar chart. \n",
    "# Use \"Trip Avg Temp\" as your Title\n",
    "# Use the average temperature for the y value\n",
    "# Use the peak-to-peak (tmax-tmin) value as the y error bar (yerr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the total amount of rainfall per weather station for your trip dates using the previous year's matching dates.\n",
    "# Sort this in descending order by precipitation amount and list the station, name, latitude, longitude, and elevation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional Challenge Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a query that will calculate the daily normals \n",
    "# (i.e. the averages for tmin, tmax, and tavg for all historic data matching a specific month and day)\n",
    "\n",
    "def daily_normals(date):\n",
    "    \"\"\"Daily Normals.\n",
    "    \n",
    "    Args:\n",
    "        date (str): A date string in the format '%m-%d'\n",
    "        \n",
    "    Returns:\n",
    "        A list of tuples containing the daily normals, tmin, tavg, and tmax\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    sel = [func.min(Measurement.tobs), func.avg(Measurement.tobs), func.max(Measurement.tobs)]\n",
    "    return session.query(*sel).filter(func.strftime(\"%m-%d\", Measurement.date) == date).all()\n",
    "    \n",
    "daily_normals(\"01-01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the daily normals for your trip\n",
    "# push each tuple of calculations into a list called `normals`\n",
    "\n",
    "# Set the start and end date of the trip\n",
    "\n",
    "# Use the start and end date to create a range of dates\n",
    "\n",
    "# Stip off the year and save a list of %m-%d strings\n",
    "\n",
    "# Loop through the list of %m-%d strings and calculate the normals for each date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the previous query results into a Pandas DataFrame and add the `trip_dates` range as the `date` index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the daily normals as an area plot with `stacked=False`\n"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "nteract": {
   "version": "0.12.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
